{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ia4C7soOpwaf",
    "outputId": "14ddd57b-2c8f-4ff9-c6ad-ff98ac7b3ede"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"Project3.csv\") # Importing the data in dataframe\n",
    "df.drop(df.columns[[0]],1,inplace=True) # Dropping the column named ID from the dataframe\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "F1MPfpfpuann"
   },
   "outputs": [],
   "source": [
    "# In order to calculate z-score, we need to first calculate the mean and standard deviation\n",
    "# z-score is calculated to normalize the parameters so that every parameter has equal contribution\n",
    "\n",
    "# Now Here we will calculate the mean of the data\n",
    "rows=df.shape[0]\n",
    "cols=df.shape[1]\n",
    "\n",
    "avg_arr = [0]*cols\n",
    "for y in range(0,cols):\n",
    "  sum=0\n",
    "  for x in range(0,rows):\n",
    "    sum=sum+df.iloc[x,y]\n",
    "  sum=sum/rows\n",
    "  avg_arr[y]=sum\n",
    "# avg_arr will have the mean of all the columns stored in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "u9I1qjdZxhqf"
   },
   "outputs": [],
   "source": [
    "# Now we will calculate the standard deviation of the data\n",
    "std_dev = [0]*cols\n",
    "for y in range(0,cols):\n",
    "  sum=0\n",
    "  for x in range(0,rows):\n",
    "    diff=df.iloc[x,y]-avg_arr[y]\n",
    "    diff=diff**2\n",
    "    sum=sum+diff\n",
    "  sum=sum/rows\n",
    "  sum=math.sqrt(sum)\n",
    "  std_dev[y]=sum\n",
    "# std_dev will have the standard deviation of all the columns stored in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JWdgUvDmxrrq"
   },
   "outputs": [],
   "source": [
    "# Now we will iterate over the dataframe and change every value to its z-score\n",
    "for x in range(rows):\n",
    "  for y in range(cols):\n",
    "    df.iloc[x,y]=(df.iloc[x,y]-avg_arr[y])/std_dev[y] # This is the formula to get the z-score\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Yg2u-wSDUPC6"
   },
   "outputs": [],
   "source": [
    "# dist function takes 3 parameters namely idx (which is the row number - 0 indexed), k (the number of clusters), and\n",
    "# the centroids (which is a 2d array and stores the data of centroids of every cluster)\n",
    "\n",
    "# Let's suppose the value of k is 3, then centroids will have 3 rows and columns equal to the columns in dataframe\n",
    "# To sum up, each row will have all the features of the ith centroid\n",
    "\n",
    "def dist(idx,k,centroids):\n",
    "  container=0\n",
    "  mindist=math.inf\n",
    "  for i in range(k):\n",
    "    sum=0\n",
    "    for j in range(cols):\n",
    "      sum=sum+((centroids[i][j]-df.iloc[idx,j])**2)\n",
    "    if sum<mindist: \n",
    "      mindist=sum\n",
    "      container=i\n",
    "  return container\n",
    "# This function compares the distance of the point with each centroid and returns the container number whose centroid has the \n",
    "# closest distance from the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ftk-JS_AMsp8"
   },
   "outputs": [],
   "source": [
    "# Elbow method is used to get the optimal number of clusters required for the data\n",
    "# This Elbow method has been used two ways, one for returning the wss score when flag = 0 and the other for returning the cluster when flag = 1 \n",
    "def elbow(k,flag):\n",
    "  random_rows=random.sample(range(0,rows),k) # Select k random points and put them in random_rows array\n",
    "  centroids=np.zeros((k,cols)) # Initialized the centroids with all zeros\n",
    "  new_centroids=np.zeros((k,cols))\n",
    "\n",
    "  for i in range(k):\n",
    "    centroids[i]=df.iloc[random_rows[i],:] # Put the features of those random selected points in the centroids 2D array\n",
    "    # Now the centroids 2D array contains randomly selected k rows of the dataframe\n",
    "  \n",
    "  # We will perform at max 30 iterations to get the convergerd centroids of the clusters \n",
    "  itr=0\n",
    "  while(itr<30):\n",
    "    itr=itr+1\n",
    "\n",
    "    clusters=[[] for _ in range(k)] # Need to make clusters to store points in the clusters\n",
    "    \n",
    "    # This for loop puts all the points of the dataframe in the appropriate cluster\n",
    "    for idx in range(rows):\n",
    "      clusters[dist(idx,k,centroids)].append(idx)\n",
    "\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "      cluster_mean=np.mean(df.iloc[cluster],axis=0) # Mean of each feature of each cluster is calculated to \n",
    "      # get the new centroid\n",
    "      new_centroids[cluster_idx]=cluster_mean # The data is put in the new_centroids 2D array\n",
    "\n",
    "    # Condition to check the convergence of the centroids\n",
    "    cnt=0\n",
    "    for i in range(k):\n",
    "      for j in range(cols):\n",
    "        if abs(new_centroids[i][j]-centroids[i][j]) <= 1e-5: \n",
    "          cnt=cnt+1\n",
    "\n",
    "    if cnt==(k*cols) or itr==30:\n",
    "      # If the centroids converged then this condition has to be followed\n",
    "      score=0\n",
    "      for i in range(k):\n",
    "        for val in clusters[i]:\n",
    "          for j in range(cols):\n",
    "            score=score+((centroids[i][j]-df.iloc[val,j])**2)\n",
    "            \n",
    "      if flag==0:\n",
    "        return score\n",
    "      else:\n",
    "        return clusters\n",
    "    else:\n",
    "      # If the centroids have not converged till now then move to the next loop but before that update the centroid\n",
    "      centroids=new_centroids.copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Mbfv-dCgTJ8m"
   },
   "outputs": [],
   "source": [
    "# # Here we will apply Elbow method to get the optimal value of k\n",
    "# wss=[0]*10 # wss array contains the within cluster sum of squared errors\n",
    "# for k in range(1,11):\n",
    "#   wss[k-1]=elbow(k,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FByeqk05ab6u",
    "outputId": "d9fb2b94-334c-449c-afbf-e70abeda552d"
   },
   "outputs": [],
   "source": [
    "# # Once the wss score has been calculated, we need to figure out where the elbow occured\n",
    "# stslope=wss[0]-wss[1]\n",
    "# for i in range(1,11):\n",
    "#   slope=wss[i]-wss[i+1]\n",
    "#   if stslope>=10*slope:\n",
    "#     k=i+1\n",
    "#     break\n",
    "# print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Optimal value of k came out to be:  4\n"
     ]
    }
   ],
   "source": [
    "# Here is the optimized algorithm that can be used instead of above 12 lines and it works exactly the same and at the same time more efficient\n",
    "# Here we will apply Elbow method to get the optimal value of k\n",
    "# We consecutively will calculate the wss score and at the same time will figure out where the elbow occured\n",
    "wss=[0]*10 # wss array contains the within cluster sum of squared errors\n",
    "wss[0]=elbow(1,0)\n",
    "wss[1]=elbow(2,0)\n",
    "\n",
    "stslope=wss[0]-wss[1]\n",
    "for i in range(3,11):\n",
    "    wss[i-1]=elbow(i,0)\n",
    "    slope=wss[i-2]-wss[i-1]\n",
    "    if stslope>=5*slope:\n",
    "        k=i-2\n",
    "        break\n",
    "print(\"The Optimal value of k came out to be: \",k)\n",
    "# This method will save us a lot of computation hence saving a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "uFdyAjXu5f5w"
   },
   "outputs": [],
   "source": [
    "# Once we got the optimal value of k (the number of clusters), now it's time to put the points in appropriate cluster\n",
    "final_clusters=[[] for _ in range(k)]\n",
    "final_clusters=elbow(k,1)\n",
    "\n",
    "# Now we alloted the cluster to the rows\n",
    "ans=[0]*2000\n",
    "for i in range(k):\n",
    "  for val in final_clusters[i]:\n",
    "    ans[val]=i+1\n",
    "\n",
    "# print(ans)\n",
    "content=\"\"\n",
    "for i in ans:\n",
    "  content=content+str(i)+\" \"\n",
    "\n",
    "OutF=open(\"19IE10041_P3.out\",\"w\") \n",
    "OutF.write(content) # The results are printed in the file\n",
    "OutF.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
